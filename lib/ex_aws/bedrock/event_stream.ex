defmodule ExAws.Bedrock.EventStream do
  @moduledoc """
  Handle streaming of output generated by models.

  The model detail returned by `ExAws.Bedrock.get_foundation_model/1` must have:

      responseStreamingSupported = true

  This requires `hackney` otherwise we will fail at runtime. It also assumes `Jason` is available
  but we can improve this to lookup the ExAws JSON coded.

  [AWS API Docs](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ResponseStream.html)
  """

  defdelegate build_request_url(post_operation, config), to: ExAws.Request.Url, as: :build

  @content_type "application/vnd.amazon.eventstream"

  if {:module, :hackney} == Code.ensure_loaded(:hackney) &&
       Kernel.function_exported?(:hackney, :post, 4) do
    @http_ua :hackney_request.default_ua()
    @library_version Application.spec(:ex_aws_bedrock)[:vsn]
    @user_agent "#{@http_ua} ex_aws/bedrock/#{@library_version}"
    @headers [
      {"accept", @content_type},
      {"content-type", "application/json"},
      {"user-agent", @user_agent},
      {"x-amzn-bedrock-accept", "*/*"}
    ]
    @hackney_options [{:async, :once}]

    @doc """
    Stream of chunks from the response stream.

    Raises on any error.

    [AWS API Docs](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ResponseStream.html)
    """
    def stream_objects!(%{service: service, data: data} = post_operation, _opts, config) do
      encoded_data = Jason.encode!(data)
      url = build_request_url(post_operation, config)
      config = Map.put(config, :service_override, :bedrock)

      {:ok, full_headers} =
        ExAws.Auth.headers(
          :post,
          url,
          service,
          config,
          @headers,
          encoded_data
        )

      request_fun = fn [] ->
        {:ok, ref} = :hackney.post(url, full_headers, encoded_data, @hackney_options)

        receive do
          {:hackney_response, ^ref, {:status, 200, _reason}} ->
            ref

          {:hackney_response, ^ref, {:status, status, reason}} ->
            {:error, status, reason}

          {:hackney_response, ^ref, {:error, {:closed, :timeout}}} ->
            :closed
        end
      end

      stream =
        Stream.resource(
          fn -> request_fun.([]) end,
          fn
            :closed ->
              {:halt, []}

            {:error, status, reason} ->
              raise ExAws.Error, "#{to_string(status)}: #{to_string(reason)}"

            ref when is_reference(ref) ->
              :ok = :hackney.stream_next(ref)

              receive do
                {:hackney_response, ^ref, {:headers, headers}} ->
                  verify_event_stream!(headers)
                  verify_chunked!(headers)
                  {[], ref}

                {:hackney_response, ^ref, :done} ->
                  {:halt, []}

                {:hackney_response, ^ref, data} ->
                  {[data], ref}
              end
          end,
          &Function.identity/1
        )

      Stream.flat_map(stream, &decode_chunk/1)
    end

    defp verify_event_stream!(headers) do
      verify_header!(headers, "Content-Type", @content_type)
    end

    defp verify_chunked!(headers) do
      verify_header!(headers, "Transfer-Encoding", "chunked")
    end

    defp verify_header!(headers, header, expected) do
      case List.keyfind!(headers, header, 0) do
        {_, ^expected} ->
          true

        {_, content_type} ->
          raise ExAws.Error, "Accepts #{expected}, received #{to_string(content_type)}"
      end
    end
  else
    def stream_objects!(_, _, _) do
      raise "Bedrock response streaming requires hackney in your mix dependencies"
    end
  end

  @doc false
  @spec decode_chunk(binary()) :: list({:chunk, map()} | {:bad_chunk, binary(), term()})
  def decode_chunk(data) do
    decode_chunks(data, [])
  end

  defp decode_chunks(<<>>, acc), do: Enum.reverse(acc)

  defp decode_chunks(data, acc) do
    case parse_chunk(data) do
      {:ok, chunk, rest} ->
        decode_chunks(rest, [{:chunk, chunk} | acc])

      {:error, reason, rest} ->
        decode_chunks(rest, [{:bad_chunk, data, reason} | acc])

      :incomplete ->
        # May wish to buffer incomplete data
        [{:incomplete_chunk, data} | acc]
    end
  end

  @uint32_size 4
  @checksum_size 4
  # prelude_length = message_total_length + headers_length + prelude_checksum
  @prelude_length @uint32_size * 3
  # message_overhead = prelude + message_checksum
  @message_overhead @prelude_length + @checksum_size
  defp parse_chunk(
         <<
           message_total_length::unsigned-32,
           headers_length::unsigned-32,
           _prelude_checksum::unsigned-32,
           _headers::binary-size(headers_length),
           rest::binary
         >> = data
       )
       when byte_size(data) >= message_total_length do
    message_length = message_total_length - @message_overhead
    body_length = message_length - headers_length

    if byte_size(rest) >= body_length + @checksum_size do
      <<
        body::binary-size(body_length),
        _message_checksum::unsigned-32,
        next_data::binary
      >> = rest

      case process_chunk(body) do
        {:ok, chunk} ->
          {:ok, chunk, next_data}

        {:error, reason} ->
          {:error, reason, next_data}
      end
    else
      :incomplete
    end
  end

  defp parse_chunk(data) when byte_size(data) < @prelude_length do
    # Not enough data to read prelude
    :incomplete
  end

  defp parse_chunk(_data) do
    # Invalid chunk
    {:error, :invalid_chunk, <<>>}
  end

  defp process_chunk(body) do
    with {:ok, %{"bytes" => bytes}} <- Jason.decode(body),
         {:ok, json} <- Base.decode64(bytes),
         {:ok, payload} <- Jason.decode(json) do
      {:ok, payload}
    else
      {:error, error} ->
        {:error, error}

      error ->
        {:error, error}
    end
  end
end
