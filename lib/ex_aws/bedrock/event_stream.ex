defmodule ExAws.Bedrock.EventStream do
  @moduledoc """
  Handle streaming of output generated by models.

  The model detail returned by `ExAws.Bedrock.get_foundation_model/1` must have:

      responseStreamingSupported = true

  This requires `hackney` otherwise we will fail at runtime. It also assumes `Jason` is available
  but we can improve this to lookup the ExAws JSON coded.

  [AWS API Docs](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ResponseStream.html)
  """

  defdelegate build_request_url(post_operation, config), to: ExAws.Request.Url, as: :build

  @content_type "application/vnd.amazon.eventstream"

  if {:module, :hackney} == Code.ensure_loaded(:hackney) &&
       Kernel.function_exported?(:hackney, :post, 4) do
    @http_ua :hackney_request.default_ua()
    @library_version Application.spec(:ex_aws_bedrock)[:vsn]
    @user_agent "#{@http_ua} ex_aws/bedrock/#{@library_version}"
    @headers [
      {"accept", @content_type},
      {"content-type", "application/json"},
      {"user-agent", @user_agent},
      {"x-amzn-bedrock-accept", "*/*"}
    ]
    @hackney_options [{:async, :once}]

    @doc """
    Stream of chunks from the response stream.

    Raises on any error.

    [AWS API Docs](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ResponseStream.html)
    """
    def stream_objects!(%{service: service, data: data} = post_operation, opts, config) do
      encoded_data = Jason.encode!(data)
      url = build_request_url(post_operation, config)
      config = Map.put(config, :service_override, :bedrock)

      {:ok, full_headers} =
        ExAws.Auth.headers(
          :post,
          url,
          service,
          config,
          @headers,
          encoded_data
        )

      # Extract HTTP options and build hackney options with timeout configurations
      hackney_options = build_hackney_options(config, opts)

      request_fun = fn [] ->
        {:ok, ref} = :hackney.post(url, full_headers, encoded_data, hackney_options)

        receive do
          {:hackney_response, ^ref, {:status, 200, _reason}} ->
            ref

          {:hackney_response, ^ref, {:status, status, reason}} ->
            {:error, status, reason}

          {:hackney_response, ^ref, {:error, {:closed, :timeout}}} ->
            :closed
        end
      end

      stream =
        Stream.resource(
          fn -> request_fun.([]) end,
          fn
            :closed ->
              {:halt, []}

            {:error, status, reason} ->
              raise ExAws.Error, "#{to_string(status)}: #{to_string(reason)}"

            ref when is_reference(ref) ->
              :ok = :hackney.stream_next(ref)

              receive do
                {:hackney_response, ^ref, {:headers, headers}} ->
                  verify_event_stream!(headers)
                  verify_chunked!(headers)
                  {[], ref}

                {:hackney_response, ^ref, :done} ->
                  {:halt, []}

                {:hackney_response, ^ref, data} ->
                  {[data], ref}
              end
          end,
          &Function.identity/1
        )

      Stream.flat_map(stream, &decode_chunk/1)
    end

    defp verify_event_stream!(headers) do
      verify_header!(headers, "Content-Type", @content_type)
    end

    defp verify_chunked!(headers) do
      verify_header!(headers, "Transfer-Encoding", "chunked")
    end

    defp verify_header!(headers, header, expected) do
      case List.keyfind!(headers, header, 0) do
        {_, ^expected} ->
          true

        {_, content_type} ->
          raise ExAws.Error, "Accepts #{expected}, received #{to_string(content_type)}"
      end
    end
  else
    def stream_objects!(_, _, _) do
      raise "Bedrock response streaming requires hackney in your mix dependencies"
    end
  end

  @doc false
  @spec decode_chunk(binary()) :: list({:chunk, map()} | {:bad_chunk, binary(), term()})
  def decode_chunk(data) do
    decode_chunks(data, [])
  end

  defp decode_chunks(<<>>, acc), do: Enum.reverse(acc)

  defp decode_chunks(data, acc) do
    case parse_chunk(data) do
      {:ok, chunk, rest} ->
        decode_chunks(rest, [{:chunk, chunk} | acc])

      {:error, reason, rest} ->
        decode_chunks(rest, [{:bad_chunk, data, reason} | acc])

      :incomplete ->
        # May wish to buffer incomplete data
        [{:incomplete_chunk, data} | acc]
    end
  end

  @uint32_size 4
  @checksum_size 4
  # prelude_length = message_total_length + headers_length + prelude_checksum
  @prelude_length @uint32_size * 3
  # message_overhead = prelude + message_checksum
  @message_overhead @prelude_length + @checksum_size
  defp parse_chunk(
         <<
           message_total_length::unsigned-32,
           headers_length::unsigned-32,
           prelude_checksum::unsigned-32,
           headers::binary-size(headers_length),
           rest::binary
         >> = data
       )
       when byte_size(data) >= message_total_length do
    message_length = message_total_length - @message_overhead
    body_length = message_length - headers_length

    if byte_size(rest) >= body_length + @checksum_size do
      <<
        body::binary-size(body_length),
        message_checksum::unsigned-32,
        next_data::binary
      >> = rest

      prelude = <<message_total_length::unsigned-32, headers_length::unsigned-32>>

      with :ok <- verify_prelude_checksum(prelude, prelude_checksum),
           :ok <-
             verify_message_checksum(prelude, prelude_checksum, headers, body, message_checksum),
           {:ok, chunk} <- process_chunk(body) do
        {:ok, chunk, next_data}
      else
        {:error, reason} -> {:error, reason, next_data}
      end
    else
      :incomplete
    end
  end

  defp parse_chunk(data) when byte_size(data) < @prelude_length do
    :incomplete
  end

  defp parse_chunk(_data) do
    {:error, :invalid_chunk, <<>>}
  end

  defp verify_prelude_checksum(prelude, checksum) do
    if crc32(prelude) == checksum do
      :ok
    else
      {:error, :invalid_prelude_checksum}
    end
  end

  defp verify_message_checksum(prelude, prelude_checksum, headers, body, checksum) do
    message = prelude <> <<prelude_checksum::unsigned-32>> <> headers <> body

    if crc32(message) == checksum do
      :ok
    else
      {:error, :invalid_message_checksum}
    end
  end

  defp crc32(data) do
    :erlang.crc32(data)
  end

  defp process_chunk(body) do
    case Jason.decode(body) do
      # Format for invoke_model_with_response_stream
      {:ok, %{"bytes" => bytes}} ->
        with {:ok, json} <- Base.decode64(bytes),
             {:ok, payload} <- Jason.decode(json) do
          {:ok, payload}
        end

      # Process converse_stream events - simple direct transformation
      {:ok, payload} when is_map(payload) ->
        process_converse_chunk(payload)

      # Format for other direct JSON without base64 encoding
      {:ok, payload} ->
        {:ok, payload}

      {:error, error} ->
        {:error, error}
    end
  end

  @doc false
  @spec process_converse_chunk(map()) :: {:ok, map()}
  defp process_converse_chunk(payload) do
    # First remove the "p" field which is internal metadata
    payload = Map.drop(payload, ["p"])

    # Map the AWS event format to the expected output structure
    processed_payload =
      case payload do
        # Message start event
        %{"role" => "assistant"} ->
          %{"messageStart" => %{"role" => "assistant"}}

        # Content block delta with text
        %{"contentBlockIndex" => index, "delta" => %{"text" => text}} ->
          %{"contentBlockDelta" => %{"delta" => %{"text" => text}, "contentBlockIndex" => index}}

        # Content block delta with tool use
        %{"contentBlockIndex" => index, "delta" => %{"toolUse" => tool_use}} ->
          %{
            "contentBlockDelta" => %{
              "delta" => %{"toolUse" => tool_use},
              "contentBlockIndex" => index
            }
          }

        # Content block start
        %{"contentBlockIndex" => index, "start" => start} ->
          %{"contentBlockStart" => %{"start" => start, "contentBlockIndex" => index}}

        # Content block stop
        %{"contentBlockIndex" => index}
        when not is_map_key(payload, "delta") and not is_map_key(payload, "start") ->
          %{"contentBlockStop" => %{"contentBlockIndex" => index}}

        # Message stop
        %{"stopReason" => reason} ->
          %{"messageStop" => %{"stopReason" => reason}}

        # Metadata
        %{"usage" => usage, "metrics" => metrics} ->
          %{"metadata" => %{"usage" => usage, "metrics" => metrics}}

        # Other events pass through unchanged
        _ ->
          payload
      end

    {:ok, processed_payload}
  end

  # Build hackney options by merging base options with HTTP timeout configurations
  defp build_hackney_options(config, opts) do
    # Start with base options
    base_options = @hackney_options

    # Extract HTTP options from ExAws config
    http_opts = get_http_opts(config, opts)

    # Extract timeout-related options and convert to hackney format
    timeout_options = extract_timeout_options(http_opts)

    # Merge all options, with timeout_options taking precedence
    base_options ++ timeout_options
  end

  # Get HTTP options from config and opts, with opts taking precedence
  defp get_http_opts(config, opts) do
    config_http_opts = Map.get(config, :http_opts, [])

    opts_http_opts =
      case opts do
        nil -> []
        opts when is_list(opts) -> Keyword.get(opts, :http_opts, [])
        _ -> []
      end

    # Merge config options with opts, opts taking precedence
    Keyword.merge(config_http_opts, opts_http_opts)
  end

  # Extract timeout options that hackney understands
  defp extract_timeout_options(http_opts) do
    timeout_keys = [:connect_timeout, :recv_timeout, :timeout]

    timeout_keys
    |> Enum.filter(fn key -> Keyword.has_key?(http_opts, key) end)
    |> Enum.map(fn key -> {key, Keyword.get(http_opts, key)} end)
  end
end
